-Neurons just hold a number between 0.0 - 1.0
    -Number is called activation
    - 0 = black, 1 = white
    -All the neurons make up first layer
-Last layer
    -Each for digit 0-9
    -Activation here represents model's confidence on result
-Activations in 1 layer determine activation in next layer
-Break image into sub-components
-Second layer
    -Weigh the connections between current neuron and the neurons from the first layer
    -Compute weighed sum of first-layer Activations
        -Gives any number
    -Use sigmoid function to squish 0-1
        1 / (1 + e^(-x))
    -Activation measures how positive the weighted sum is
    -If you only want neuron to activate when weighed sum > 10:
        -Bias to inactivity
        -Subtract 10 from sum before plugging into sigmoid
-Learning: Finding right weights/biases
-
-Hidden layers
    -